{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modeling_biencoder import BiEncoder_Normer\n",
    "# import os\n",
    "# os.environ['CUDA_VISIBLE_DEVICES']=\"1\"\n",
    "from transformers import AutoTokenizer, AutoModel, AutoConfig\n",
    "import transformers\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from pytorch_metric_learning import miners, losses, distances\n",
    "from typing import List, Optional, Tuple, Union\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pytorch_metric_learning.distances import CosineSimilarity\n",
    "from pytorch_metric_learning.utils import loss_and_miner_utils as lmu\n",
    "from torch.optim import AdamW\n",
    "from transformers import Trainer\n",
    "import datasets\n",
    "from safetensors.torch import load_file\n",
    "import joblib\n",
    "from sklearn.preprocessing import normalize\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import glob\n",
    "from pathlib import Path\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## setting required before running\n",
    "context_encoder_path = 'path_to_context_encoder_initial_checkpoint'\n",
    "concept_encoder_path = 'path_to_concept_encoder_initial_checkpoint'\n",
    "ADD_SOFT_TOKEN = True\n",
    "MAX_LENGTH = \"max_length_here\"\n",
    "SAFE_TENSOR_FILE = 'path_to_saved_parameters'\n",
    "UNIENCODER = False\n",
    "if UNIENCODER:\n",
    "    mean_pooling = True\n",
    "else:\n",
    "    mean_pooling = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_tokenizer = AutoTokenizer.from_pretrained(context_encoder_path)\n",
    "config = AutoConfig.from_pretrained(context_encoder_path)\n",
    "biencoder = BiEncoder_Normer(concept_encoder= concept_encoder_path, context_encoder=context_encoder_path, mean_pooling= mean_pooling,projection= 'linear', config = config)\n",
    "if ADD_SOFT_TOKEN:\n",
    "    new_special_tokens = {'additional_special_tokens': ['[SOFT]']}\n",
    "    context_tokenizer.add_special_tokens(new_special_tokens)\n",
    "    biencoder.context_encoder.resize_token_embeddings(len(context_tokenizer))\n",
    "state_dict = load_file(SAFE_TENSOR_FILE)\n",
    "biencoder.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function_test(datapoint):\n",
    "    if ADD_SOFT_TOKEN:\n",
    "        special_id = context_tokenizer.additional_special_tokens_ids[0]\n",
    "    \n",
    "    model_inputs = {\n",
    "        \"concept_input_ids\": None,\n",
    "        \"context_input_ids\": None,\n",
    "        \"labels\": None\n",
    "    }\n",
    "    mentions = str(datapoint['mention'])\n",
    "    contexts = str(datapoint['sentence'])\n",
    "    start, end = datapoint['char_pos']\n",
    "    \n",
    "    if ADD_SOFT_TOKEN and start is not None:\n",
    "        contexts = contexts[:start] + '[SOFT] ' + contexts[start:end] + ' [SOFT]' + contexts[end:]\n",
    "    \n",
    "    if UNIENCODER:\n",
    "        context_input_ids = context_tokenizer.encode(contexts, return_tensors= 'pt')[0]\n",
    "    else:\n",
    "        context_input_ids = context_tokenizer.encode(mentions,contexts, return_tensors= 'pt')[0]\n",
    "    \n",
    "    if ADD_SOFT_TOKEN and start is not None:\n",
    "        indices = torch.where(context_input_ids == special_id)[0]\n",
    "        mention_start = indices[0] + 1\n",
    "        mention_end = indices[1]\n",
    "    else:\n",
    "        mention_start = 1\n",
    "        mention_end = len(context_input_ids) - 1\n",
    "\n",
    "    model_inputs[\"context_input_ids\"] = context_input_ids.tolist()\n",
    "    model_inputs[\"mention_start\"] = mention_start\n",
    "    model_inputs[\"mention_end\"] = mention_end\n",
    "    \n",
    "    return model_inputs\n",
    "\n",
    "def data_collator(batch):\n",
    "    len_max_batch_context = [len(batch[i].get(\"context_input_ids\"))\n",
    "                     for i in range(len(batch))]\n",
    "    len_max_batch_context = min(MAX_LENGTH, max(len_max_batch_context))\n",
    "\n",
    "\n",
    "    batch_context_input_ids = []\n",
    "    batch_context_attention_mask = []\n",
    "\n",
    "    batch_context_mean_inputs_mask = []\n",
    "\n",
    "    for ba in batch:\n",
    "        context_input_ids, mention_start, mention_end = ba.get(\"context_input_ids\"), ba.get(\"mention_start\"), ba.get(\"mention_end\")\n",
    "        \n",
    "        context_len_padding = len_max_batch_context - len(context_input_ids) \n",
    "        context_input_ids = context_input_ids[:len_max_batch_context] + [0] * (context_len_padding)\n",
    "        context_attention_mask = torch.ones(len_max_batch_context,dtype=torch.long)\n",
    "        if context_len_padding != 0:\n",
    "            context_attention_mask[-context_len_padding:] = 0\n",
    "        tensor_context_input_ids = torch.tensor(context_input_ids, dtype=torch.long)\n",
    "        batch_context_input_ids.append(tensor_context_input_ids)\n",
    "        batch_context_attention_mask.append(context_attention_mask)\n",
    "        \n",
    "        context_mean_inputs_mask = torch.zeros(len_max_batch_context,dtype=torch.long)\n",
    "        context_mean_inputs_mask[mention_start: mention_end] = 1\n",
    "        batch_context_mean_inputs_mask.append(context_mean_inputs_mask)\n",
    "        \n",
    "    batch_context_input_ids = torch.stack(batch_context_input_ids)\n",
    "    batch_context_attention_mask = torch.stack(batch_context_attention_mask)\n",
    "    batch_context_mean_inputs_mask = torch.stack(batch_context_mean_inputs_mask)\n",
    "\n",
    "    input_dict = {\n",
    "                \"context_input_ids\": batch_context_input_ids,\n",
    "                \"context_attention_mask\":batch_context_attention_mask,\n",
    "                \"context_mean_inputs_mask\":batch_context_mean_inputs_mask,\n",
    "                }\n",
    "    return input_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "test_file = 'test_file.csv'\n",
    "test = pd.read_csv(test_file, keep_default_na= False)\n",
    "test['char_pos'] = test['char_pos'].apply(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = datasets.Dataset.from_pandas(test).map(preprocess_function_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_inputs = data_collator(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_embeds = biencoder.query_embedding(model_inputs , device='cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## save embeddings\n",
    "path = 'path_to_embeddings'\n",
    "with open(path,'wb') as f:\n",
    "    joblib.dump(query_embeds,f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
